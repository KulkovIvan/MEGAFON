{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4872f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e1e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_df_by_target(df, target_name):\n",
    "    num_0 = len(df[df[target_name] == 0])\n",
    "    num_1 = len(df[df[target_name] == 1])\n",
    "    undersampled_data = pd.concat([df[df[target_name] == 0].sample(num_1), df[df[target_name] == 1]])\n",
    "\n",
    "    return undersampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fa2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(estimator, X, y, params_grid, scoring='f1'):\n",
    "    gsc = GridSearchCV(estimator, params_grid, scoring=scoring, cv=3, n_jobs=-1)\n",
    "\n",
    "    gsc.fit(X, y)\n",
    "    print(\"Best %s score: %.2f\" % (scoring, gsc.best_score_))\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gsc.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "\n",
    "    for i, params in enumerate(gsc.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (gsc.cv_results_['mean_test_score'][i], gsc.cv_results_['std_test_score'][i] * 2, params))\n",
    "\n",
    "    print()\n",
    "\n",
    "    return gsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9966c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treshold_search(y_true, y_pred):\n",
    "    top = [0.5, f1_score(y_true, y_pred[: , 1] > 0.5, average='macro')]\n",
    "    for treshold in np.linspace(0, 1, 20):\n",
    "        fscore = f1_score(y_true, y_pred[: , 1] > treshold, average='macro')\n",
    "        if fscore > top[1]:\n",
    "            top[0] = treshold\n",
    "            top[1] = fscore\n",
    "    print(f'Лучшая отсечка : {top[0]}, Метрика F1_macro: {top[1]}')\n",
    "    print(\"=\" * 80)\n",
    "    print(classification_report(y_true, y_pred[:, 1] > top[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03aefef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_train(prep_data_df, FEATURES_DATA):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    #prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = prep_data_df.duplicated('id').astype(int)\n",
    "\n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    train_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(train_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "\n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "\n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    result_data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    result_data = result_data.set_index(['Unnamed: 0'])\n",
    "    result_data.index.name = None\n",
    "    result_data.sort_index(inplace=True)\n",
    "    \n",
    "    return result_data, train_list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82688470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_test(prep_data_df, FEATURES_DATA, train_list_index):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    #prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = (prep_data_df['id'].isin(train_list_index)).astype(int)\n",
    "\n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    test_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(test_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "\n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "\n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    \n",
    "    result_data = result_data.set_index(['Unnamed: 0'])\n",
    "    result_data.index.name = None\n",
    "    result_data.sort_index(inplace=True)\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea16c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_type_cols(merged_data):\n",
    "    X_nunique = merged_data.apply(lambda x: x.nunique(dropna=False))\n",
    "    f_all = set(X_nunique.index.tolist())\n",
    "    f_const = set(X_nunique[X_nunique == 1].index.tolist())\n",
    "    f_categorical = set(X_nunique[X_nunique <= 30].index.tolist())\n",
    "    f_numeric = (merged_data.fillna(0).astype(int).sum() - merged_data.fillna(0).sum()).abs()\n",
    "    f_numeric = set(f_numeric[f_numeric > 0].index.tolist())\n",
    "    f_binary = set(merged_data.loc[:, f_all].columns[(\n",
    "            (merged_data.loc[:, f_all].max() == 1) & \\\n",
    "            (merged_data.loc[:, f_all].min() == 0) & \\\n",
    "            (merged_data.loc[:, f_all].isnull().sum() == 0))])\n",
    "    f_categorical = f_categorical - f_const - f_binary\n",
    "    f_numeric = f_numeric - f_categorical - f_const\n",
    "\n",
    "    assert (X_nunique.shape[0] == len(f_const) + len(f_binary) + len(f_numeric) + len(f_categorical))\n",
    "\n",
    "    f_all = list(f_binary | f_categorical | f_numeric)\n",
    "    f_binary, f_categorical, f_numeric = list(f_binary), list(f_categorical), list(f_numeric)\n",
    "\n",
    "    return f_all, f_binary, f_categorical, f_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1612ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"DataFrame не содердит следующие колонки: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4ab6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DATA = 'data/features.csv'\n",
    "RANDOM_STATE = 9\n",
    "TEST_DATA = 'data/data_test.csv'\n",
    "ANSWERS = 'data/answers_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5ecba",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902b188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a37fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\offer_mark.txt\", \"r\") as file:\n",
    "    offer_mark = file.readlines()\n",
    "    offer_mark = [int(line.rstrip()) for line in offer_mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa5f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_data_test(test_df, FEATURES_DATA, offer_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb435c",
   "metadata": {},
   "source": [
    "### Загружаем модель и делаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7f9642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 992 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('data/lg_fs_model.pickle', 'rb') as f:\n",
    "    lg_fs_model =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd9e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lg_fs_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba71479",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab5b500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_test = pd.read_csv(TEST_DATA, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c49b8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_test['target'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85882c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_test.to_csv(ANSWERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a222488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3130519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.125394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.800121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>0.125264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547413200</td>\n",
       "      <td>0.094865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>0.123542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71226</th>\n",
       "      <td>2502453</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.094374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71227</th>\n",
       "      <td>1693213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.123157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71228</th>\n",
       "      <td>1891350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.123371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71229</th>\n",
       "      <td>2437172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.122696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71230</th>\n",
       "      <td>988236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.123649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71231 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  vas_id    buy_time    target\n",
       "0      3130519     2.0  1548018000  0.125394\n",
       "1      2000860     4.0  1548018000  0.800121\n",
       "2      1099444     2.0  1546808400  0.125264\n",
       "3      1343255     5.0  1547413200  0.094865\n",
       "4      1277040     2.0  1546808400  0.123542\n",
       "...        ...     ...         ...       ...\n",
       "71226  2502453     5.0  1548018000  0.094374\n",
       "71227  1693213     2.0  1548018000  0.123157\n",
       "71228  1891350     2.0  1548018000  0.123371\n",
       "71229  2437172     2.0  1548018000  0.122696\n",
       "71230   988236     2.0  1548018000  0.123649\n",
       "\n",
       "[71231 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(ANSWERS, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf382395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
