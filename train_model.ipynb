{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca2f8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc6f14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_df_by_target(df, target_name):\n",
    "    num_0 = len(df[df[target_name] == 0])\n",
    "    num_1 = len(df[df[target_name] == 1])\n",
    "    undersampled_data = pd.concat([df[df[target_name] == 0].sample(num_1), df[df[target_name] == 1]])\n",
    "\n",
    "    return undersampled_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b0d7f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(estimator, X, y, params_grid, scoring='f1'):\n",
    "    gsc = GridSearchCV(estimator, params_grid, scoring=scoring, cv=3, n_jobs=-1)\n",
    "\n",
    "    gsc.fit(X, y)\n",
    "    print(\"Best %s score: %.2f\" % (scoring, gsc.best_score_))\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gsc.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "\n",
    "    for i, params in enumerate(gsc.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (gsc.cv_results_['mean_test_score'][i], gsc.cv_results_['std_test_score'][i] * 2, params))\n",
    "\n",
    "    print()\n",
    "\n",
    "    return gsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c331701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treshold_search(y_true, y_pred):\n",
    "    top = [0.5, f1_score(y_true, y_pred[: , 1] > 0.5, average='macro')]\n",
    "    for treshold in np.linspace(0, 1, 20):\n",
    "        fscore = f1_score(y_true, y_pred[: , 1] > treshold, average='macro')\n",
    "        if fscore > top[1]:\n",
    "            top[0] = treshold\n",
    "            top[1] = fscore\n",
    "    print(f'Лучшая отсечка : {top[0]}, Метрика F1_macro: {top[1]}')\n",
    "    print(\"=\" * 80)\n",
    "    print(classification_report(y_true, y_pred[:, 1] > top[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8527cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_train(prep_data_df, FEATURES_DATA):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    #prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = prep_data_df.duplicated('id').astype(int)\n",
    "\n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    train_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(train_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "\n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "\n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    result_data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    result_data = result_data.set_index(['Unnamed: 0'])\n",
    "    result_data.index.name = None\n",
    "    result_data.sort_index(inplace=True)\n",
    "    \n",
    "    return result_data, train_list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46c2b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_test(prep_data_df, FEATURES_DATA, train_list_index):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    #prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = (prep_data_df['id'].isin(train_list_index)).astype(int)\n",
    "\n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    test_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(test_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "\n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "\n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    \n",
    "    result_data = result_data.set_index(['Unnamed: 0'])\n",
    "    result_data.index.name = None\n",
    "    result_data.sort_index(inplace=True)\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e97eeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_type_cols(merged_data):\n",
    "    X_nunique = merged_data.apply(lambda x: x.nunique(dropna=False))\n",
    "    f_all = set(X_nunique.index.tolist())\n",
    "    f_const = set(X_nunique[X_nunique == 1].index.tolist())\n",
    "    f_categorical = set(X_nunique[X_nunique <= 30].index.tolist())\n",
    "    f_numeric = (merged_data.fillna(0).astype(int).sum() - merged_data.fillna(0).sum()).abs()\n",
    "    f_numeric = set(f_numeric[f_numeric > 0].index.tolist())\n",
    "    f_binary = set(merged_data.loc[:, f_all].columns[(\n",
    "            (merged_data.loc[:, f_all].max() == 1) & \\\n",
    "            (merged_data.loc[:, f_all].min() == 0) & \\\n",
    "            (merged_data.loc[:, f_all].isnull().sum() == 0))])\n",
    "    f_categorical = f_categorical - f_const - f_binary\n",
    "    f_numeric = f_numeric - f_categorical - f_const\n",
    "\n",
    "    assert (X_nunique.shape[0] == len(f_const) + len(f_binary) + len(f_numeric) + len(f_categorical))\n",
    "\n",
    "    f_all = list(f_binary | f_categorical | f_numeric)\n",
    "    f_binary, f_categorical, f_numeric = list(f_binary), list(f_categorical), list(f_numeric)\n",
    "\n",
    "    return f_all, f_binary, f_categorical, f_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "769338a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"DataFrame не содердит следующие колонки: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846930a",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05bbcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "777ec013",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 'data/data_train.csv'\n",
    "FEATURES_DATA = 'data/features.csv'\n",
    "RANDOM_STATE = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ea1ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['buy_time'] = pd.to_datetime(train_df['buy_time'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a600c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = undersample_df_by_target(train_df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c18513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, true_offers_ids = preprocess_data_train(X_train, FEATURES_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d84387f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/offer_mark.txt\", \"w\") as file:\n",
    "    print(*true_offers_ids, file=file, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6da963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f71cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('target', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3293d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_all, f_binary, f_categorical, f_numeric = select_type_cols(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4ab5e",
   "metadata": {},
   "source": [
    "#### Обучение Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e225995",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prep_pipeline = make_pipeline(\n",
    "    ColumnSelector(columns=f_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            ColumnSelector(f_numeric),\n",
    "            SimpleImputer(strategy=\"mean\"),\n",
    "            StandardScaler()\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            ColumnSelector(f_categorical),\n",
    "            SimpleImputer(strategy=\"most_frequent\"),\n",
    "            OneHotEncoder(handle_unknown='ignore')\n",
    "        )),\n",
    "        (\"boolean_features\", make_pipeline(\n",
    "            ColumnSelector(f_binary),\n",
    "        ))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51db7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_fs_pipe = make_pipeline(\n",
    "    f_prep_pipeline,\n",
    "    SelectFromModel(LogisticRegression(penalty='l1', random_state=RANDOM_STATE, solver='liblinear'), max_features = 29),\n",
    "    LogisticRegression(random_state=RANDOM_STATE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13fd7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline',\n",
       "                 Pipeline(steps=[('columnselector',\n",
       "                                  ColumnSelector(columns=['64', '80', '182',\n",
       "                                                          '198', '166',\n",
       "                                                          'monthday', '169',\n",
       "                                                          '40', '184', '138',\n",
       "                                                          '50', '5', '26',\n",
       "                                                          '248', '127', '240',\n",
       "                                                          '143', '171', '136',\n",
       "                                                          '44', '74', '93',\n",
       "                                                          '107', '188', '129',\n",
       "                                                          '239', '157', '251',\n",
       "                                                          '114', '124', ...])),\n",
       "                                 ('featureunion',\n",
       "                                  FeatureUnion(transformer_list=[('numeric_features',\n",
       "                                                                  Pipeline(steps=...\n",
       "                                                                                  ('onehotencoder',\n",
       "                                                                                   OneHotEncoder(handle_unknown='ignore'))])),\n",
       "                                                                 ('boolean_features',\n",
       "                                                                  Pipeline(steps=[('columnselector',\n",
       "                                                                                   ColumnSelector(columns=['not_first_offer']))]))]))])),\n",
       "                ('selectfrommodel',\n",
       "                 SelectFromModel(estimator=LogisticRegression(penalty='l1',\n",
       "                                                              random_state=9,\n",
       "                                                              solver='liblinear'),\n",
       "                                 max_features=29)),\n",
       "                ('logisticregression', LogisticRegression(random_state=9))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_fs_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5527a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lg_fs_model.pickle', 'wb') as f:\n",
    "    pickle.dump(lg_fs_pipe, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "205e52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba_train = lg_fs_pipe.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ba96131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая отсечка : 0.5263157894736842, Метрика F1_macro: 0.8884699436162535\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89     60186\n",
      "         1.0       0.87      0.91      0.89     60186\n",
      "\n",
      "    accuracy                           0.89    120372\n",
      "   macro avg       0.89      0.89      0.89    120372\n",
      "weighted avg       0.89      0.89      0.89    120372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treshold_search(y_train, preds_proba_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8679360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
